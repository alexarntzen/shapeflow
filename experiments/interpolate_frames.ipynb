{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate human running and walking frames\n",
    "\n",
    "In this experiment we interpolate between two  human frames; one walking frame and one running frame. We compare both latent space and feature space interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from signatureshape.animation import fetch_animation_id_set, fetch_animations\n",
    "from signatureshape.animation.src.mayavi_animate import mayavi_animate\n",
    "\n",
    "import extratorch as etorch\n",
    "import shapeflow as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make reproducible\n",
    "seed = torch.manual_seed(0)\n",
    "\n",
    "# better plotting\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")\n",
    "matplotlib.rcParams.update({\"font.size\": 12})\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")\n",
    "plt.style.use(\"tableau-colorblind10\")\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load and standardize motion capture data. (Same as other notebooks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume all have the same skeleton\n",
    "print(\"Loading mocap data:\")\n",
    "# walk  data\n",
    "walk_subjects = [\"07\", \"08\", \"35\", \"16\"]\n",
    "\n",
    "walk_animations = []\n",
    "walk_desc = []\n",
    "for s in walk_subjects:\n",
    "    for t in fetch_animations(100, subject_file_name=(s + \".asf\")):\n",
    "        if t[2][:4] == \"walk\":\n",
    "            walk_animations.append(t[1])\n",
    "            walk_desc.append(t[2])\n",
    "\n",
    "walk_animations_train_frame = sum(\n",
    "    len(anim.get_frames()) for anim in walk_animations[:18]\n",
    ")\n",
    "\n",
    "# run data\n",
    "run_subjects = [\"09\", \"16\", \"35\"]\n",
    "run_animations = []\n",
    "run_skeletons = []\n",
    "for s in run_subjects:\n",
    "\n",
    "    for t in fetch_animations(100, subject_file_name=(s + \".asf\")):\n",
    "        if t[2][:3] == \"run\":\n",
    "            run_skeletons.append(t[0])\n",
    "            run_animations.append(t[1])\n",
    "\n",
    "print(\"Convert to array:\")\n",
    "walk_angle_array = sf.utils.animation_to_eulers(\n",
    "    walk_animations,\n",
    "    reduce_shape=True,\n",
    "    remove_root=True,\n",
    "    deg2rad=True,\n",
    "    skeleton=run_skeletons[0],\n",
    "    max_frame_count=240,\n",
    ")\n",
    "run_angle_array = sf.utils.animation_to_eulers(\n",
    "    run_animations,\n",
    "    reduce_shape=True,\n",
    "    remove_root=True,\n",
    "    deg2rad=True,\n",
    "    skeleton=run_skeletons[0],\n",
    "    max_frame_count=240,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_angle_tensor_ = torch.tensor(walk_angle_array, dtype=torch.float32)\n",
    "run_angle_tensor_ = torch.tensor(run_angle_array, dtype=torch.float32)\n",
    "wr_angle_tensor_ = torch.cat((walk_angle_tensor_, run_angle_tensor_))\n",
    "\n",
    "# standardize\n",
    "std, mean = torch.std_mean(wr_angle_tensor_, dim=0)\n",
    "wr_angle_tensor_norm = (wr_angle_tensor_ - mean) / std\n",
    "run_angle_tensor_norm = (run_angle_tensor_ - mean) / std\n",
    "walk_angle_tensor_norm = (walk_angle_tensor_ - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_walk = torch.utils.data.TensorDataset(walk_angle_tensor_norm)\n",
    "data_run = torch.utils.data.TensorDataset(run_angle_tensor_norm)\n",
    "data = torch.utils.data.TensorDataset(wr_angle_tensor_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify model and training parameters, also define some functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "DIR = \"../figures/interpolate_frames/\"\n",
    "SET_NAME = \"res_2\"\n",
    "PATH_FIGURES = os.path.join(DIR, SET_NAME)\n",
    "########\n",
    "\n",
    "event_shape = data[0][0].shape\n",
    "base_dist = dist.Independent(\n",
    "    dist.Normal(loc=torch.zeros(event_shape), scale=torch.ones(event_shape)), 1\n",
    ")\n",
    "\n",
    "lr_scheduler = lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optim, mode=\"min\", factor=0.5, patience=10, verbose=True\n",
    ")\n",
    "num_layers = 3\n",
    "MODEL_PARAMS = {\n",
    "    \"model\": [sf.nf.get_flow],\n",
    "    \"get_transform\": [sf.transforms.get_residual_transform],\n",
    "    \"base_dist\": [base_dist],\n",
    "    \"inverse_model\": [True],\n",
    "    \"compose\": [True],\n",
    "    \"hidden_features\": [[44] * num_layers],\n",
    "    \"hidden_layers\": [[3] * num_layers],\n",
    "    \"n_exact_terms\": [[4] * num_layers],\n",
    "    \"n_samples\": [[10] * num_layers],\n",
    "}\n",
    "\n",
    "\n",
    "TRAINING_PARAMS = {\n",
    "    \"batch_size\": [3000],\n",
    "    \"compute_loss\": [sf.nf.monte_carlo_dkl_loss],\n",
    "    \"verbose\": True,\n",
    "    \"post_batch\": sf.get_post_step_lipchitz(5),\n",
    "    \"verbose_interval\": [20],\n",
    "    \"optimizer\": [\"ADAM\"],\n",
    "    \"num_epochs\": [300],\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"lr_scheduler\": [lr_scheduler],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create parameter iterators\n",
    "model_params_iter = etorch.create_subdictionary_iterator(MODEL_PARAMS, product=True)\n",
    "training_params_iter = etorch.create_subdictionary_iterator(\n",
    "    TRAINING_PARAMS, product=True\n",
    ")\n",
    "\n",
    "# train model and return results\n",
    "cv_results = etorch.k_fold_cv_grid(\n",
    "    model_params=model_params_iter,\n",
    "    fit=etorch.fit_module,\n",
    "    training_params=training_params_iter,\n",
    "    data=data,\n",
    "    verbose=True,\n",
    "    trials=1,\n",
    "    shuffle_folds=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store and plot results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etorch.plotting.plot_result(\n",
    "    path_figures=PATH_FIGURES,\n",
    "    **cv_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve model form results dict\n",
    "flow = cv_results[\"models\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting probability we need more accuracy. Use brute force jacobian calculation\n",
    "for i in range(len(flow.bijector.bijectors)):\n",
    "    flow.bijector.bijectors[i].model.iresblock.exact_trace = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = base_dist.sample([100])\n",
    "print(\"Log vals:\")\n",
    "\n",
    "print(\"Noise :\", flow.log_prob(noise).mean().item())\n",
    "print(\"Train data:\", flow.log_prob(data[:][0]).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_two frames\n",
    "i, j = 50, -2\n",
    "x_first_frame = data_walk[i : i + 1][0]\n",
    "x_second_frame = data_run[j : j + 1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate in latent space\n",
    "\n",
    "z1 = flow.rnormalize(x_first_frame)\n",
    "z2 = flow.rnormalize(x_second_frame)\n",
    "line_ = torch.linspace(0, 1, 240)\n",
    "line = torch.unsqueeze(line_, 1)\n",
    "\n",
    "# create line in latent space\n",
    "interp_line_z = z1 * line + z2 * (1 - line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform line from latent to feature space\n",
    "x_interpolated = flow.bijector.forward(interp_line_z)\n",
    "\n",
    "# feature space interpolation\n",
    "x_interpolated_lin = x_first_frame * line + x_second_frame * (1 - line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot probability of paths in feature space\n",
    "with torch.no_grad():\n",
    "    lat_log_prob = torch.mean(\n",
    "        torch.stack([flow.log_prob(x_interpolated) for a in range(10)]), dim=0\n",
    "    )\n",
    "    lin_log_prob = torch.mean(\n",
    "        torch.stack([flow.log_prob(x_interpolated_lin) for a in range(10)]), dim=0\n",
    "    )\n",
    "    plt.plot(line, torch.exp(lat_log_prob), \"-\", label=\"Latent space interpolation\")\n",
    "    plt.plot(line, torch.exp(lin_log_prob), \"-.\", label=\"Feature space interpolation\")\n",
    "    plt.xlabel(\"$t$\")\n",
    "    plt.ylabel(\"$p_{T(Z)}$\")\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    os.path.join(\n",
    "        PATH_FIGURES,\n",
    "        \"interpolation_prob.pdf\",\n",
    "    ),\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make animations:\n",
    "skel = copy.deepcopy(run_skeletons[0])\n",
    "\n",
    "anim_test = copy.deepcopy(walk_animations[0])\n",
    "anim_first = copy.deepcopy(walk_animations[0])\n",
    "anim_second = copy.deepcopy(walk_animations[0])\n",
    "anim_test_lin = copy.deepcopy(walk_animations[0])\n",
    "anim_first.from_numpy_array(sf.utils.data_to_motion_array(x_first_frame * std + mean))\n",
    "anim_second.from_numpy_array(sf.utils.data_to_motion_array(x_second_frame * std + mean))\n",
    "anim_test.from_numpy_array(sf.utils.data_to_motion_array(x_interpolated * std + mean))\n",
    "anim_test_lin.from_numpy_array(\n",
    "    sf.utils.data_to_motion_array(x_interpolated_lin * std + mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show walking frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = mayavi_animate(\n",
    "    skel,\n",
    "    anim_first,\n",
    "    offset=[0, 0, 0],\n",
    "    continuous=False,\n",
    "    fixed_cam=False,\n",
    "    frame_limit=-1,\n",
    "    save_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show running frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = mayavi_animate(\n",
    "    skel,\n",
    "    anim_second,\n",
    "    offset=[0, 0, 0],\n",
    "    continuous=False,\n",
    "    fixed_cam=False,\n",
    "    frame_limit=-1,\n",
    "    save_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show animation of linear latent space interpolation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = mayavi_animate(\n",
    "    skel,\n",
    "    anim_test,\n",
    "    offset=[0, 0, 0],\n",
    "    continuous=False,\n",
    "    fixed_cam=False,\n",
    "    frame_limit=-1,\n",
    "    save_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show animation of linear feature space interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = mayavi_animate(\n",
    "    skel,\n",
    "    anim_test_lin,\n",
    "    offset=[0, 0, 0],\n",
    "    continuous=False,\n",
    "    fixed_cam=False,\n",
    "    frame_limit=-1,\n",
    "    save_path=None,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
