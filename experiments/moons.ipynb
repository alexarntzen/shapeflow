{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test wrapper on moons\n",
    "\n",
    "Test that we can use `flowtorch` with transformations from `nflows`. \n",
    "\n",
    "Example is modifies  from [nflows](https://github.com/bayesiains/nflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation\n",
    "from nflows.flows import realnvp, autoregressive\n",
    "\n",
    "import shapeflow as sf\n",
    "\n",
    "import flowtorch.distributions as ftdist\n",
    "\n",
    "from shapeflow import ModuleBijector, WrapInverseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print train data\n",
    "x, y = datasets.make_moons(128, noise=0.1)\n",
    "plt.scatter(x[:, 0], x[:, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model\n",
    "num_layers = 5\n",
    "dims = 2\n",
    "base_dist_nflows = StandardNormal(shape=[2])\n",
    "base_dist = torch.distributions.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "\n",
    "transforms = []\n",
    "for _ in range(num_layers):\n",
    "    transforms.append(ReversePermutation(features=2))\n",
    "    transforms.append(\n",
    "        MaskedAffineAutoregressiveTransform(features=2, hidden_features=4)\n",
    "    )\n",
    "transform = CompositeTransform(transforms)\n",
    "bijector = WrapInverseModel(model=transform)\n",
    "\n",
    "flow = ftdist.Flow(bijector=bijector, base_dist=base_dist)\n",
    "optimizer = optim.Adam(flow.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the wrapper works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 5000\n",
    "for i in range(num_iter):\n",
    "    x, y = datasets.make_moons(128, noise=0.1)\n",
    "    x = torch.tensor(x, dtype=torch.float32)\n",
    "    optimizer.zero_grad()\n",
    "    loss = -flow.log_prob(value=x).mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        xline = torch.linspace(-1.5, 2.5)\n",
    "        yline = torch.linspace(-0.75, 1.25)\n",
    "        xgrid, ygrid = torch.meshgrid(xline, yline)\n",
    "        xyinput = torch.cat([xgrid.reshape(-1, 1), ygrid.reshape(-1, 1)], dim=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            zgrid = flow.log_prob(xyinput).exp().reshape(100, 100)\n",
    "        plt.contourf(xgrid.numpy(), ygrid.numpy(), zgrid.numpy())\n",
    "        plt.title(\"iteration {}\".format(i + 1))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}