{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test wrapper on moons\n",
    "\n",
    "Test that we can use `flowtorch` with transformations from `nflows`.\n",
    "\n",
    "Example is modifies  from [nflows](https://github.com/bayesiains/nflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from itertools import chain\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "import flowtorch as ft\n",
    "import flowtorch.distributions as ftdist\n",
    "import nflows\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation\n",
    "import normflow as nf\n",
    "\n",
    "from signatureshape.animation import fetch_animation_id_set, fetch_animations\n",
    "from signatureshape.animation.src.mayavi_animate import mayavi_animate\n",
    "\n",
    "from deepthermal.validation import (\n",
    "    create_subdictionary_iterator,\n",
    "    k_fold_cv_grid,\n",
    "    add_dictionary_iterators,\n",
    ")\n",
    "from deepthermal.FFNN_model import fit_FFNN\n",
    "from deepthermal.plotting import plot_result\n",
    "\n",
    "import shapeflow as sf\n",
    "import shapeflow.normalizing_flows\n",
    "\n",
    "# make reproducible\n",
    "seed = torch.manual_seed(0)\n",
    "\n",
    "# better formats\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data as so3\n",
    "# we assume all have the same skeleton\n",
    "print(\"Loading mocap data:\")\n",
    "# walk  data\n",
    "walk_subjects = [\"07\", \"08\", \"35\", \"16\"]\n",
    "walk_animations = []\n",
    "for s in walk_subjects:\n",
    "    for t in fetch_animations(100, subject_file_name=(s + \".asf\")):\n",
    "        if t[2][:4] == \"walk\":\n",
    "            walk_animations.append(t[1])\n",
    "\n",
    "walk_animations_train_frame = sum(\n",
    "    len(anim.get_frames()) for anim in walk_animations[:18]\n",
    ")\n",
    "\n",
    "# run data\n",
    "run_subjects = [\"09\", \"16\", \"35\"]\n",
    "run_animations = []\n",
    "run_skeletons = []\n",
    "for s in run_subjects:\n",
    "\n",
    "    for t in fetch_animations(100, subject_file_name=(s + \".asf\")):\n",
    "        if t[2][:3] == \"run\":\n",
    "            run_skeletons.append(t[0])\n",
    "            run_animations.append(t[1])\n",
    "\n",
    "print(\"Convert to array:\")\n",
    "walk_angle_array = sf.utils.animation_to_eulers(\n",
    "    walk_animations, reduce_shape=False, remove_root=True, deg2rad=True\n",
    ")\n",
    "run_angle_array = sf.utils.animation_to_eulers(\n",
    "    run_animations,\n",
    "    reduce_shape=False,\n",
    "    remove_root=True,\n",
    "    deg2rad=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try animating this\n",
    "# print(\"len: \", len(run_angle_array))\n",
    "# id = 0\n",
    "# from animation.src.mayavi_animate import mayavi_animate\n",
    "# from animation.src.animation import Animation\n",
    "# anim, skel = run_animations[id], run_skeletons[id]\n",
    "# anim.from_numpy_array( walk_angle_array[0].T)\n",
    "# mayavi_animate(skel, anim, offset=anim._offset, continuous=True, fixed_cam = False, frame_limit = -1, save_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skel, anim, desc = fetch_animations(1, subject_file_name=walk_subjects[0]+\".asf\")\n",
    "# skel2, anim, desc = fetch_animations(1, subject_file_name=run_subjects[0]+\".asf\")\n",
    "# skel.bones.keys() == skel2.bones.keys()\n",
    "# for bone_name, bone_obj in skel.bones.items():\n",
    "#     pass\n",
    "#     print(bone_name, \":\")\n",
    "#     print([dof for dof in bone_obj.dof], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data since it takes so long to get\n",
    "\n",
    "np.save(\"walk_angle_array_full.npy\", walk_angle_array)\n",
    "walk_angle_tensor = torch.tensor(\n",
    "    np.load(\"walk_angle_array_full.npy\", allow_pickle=False)\n",
    ").float()\n",
    "\n",
    "\n",
    "np.save(\"run_angle_array_full.npy\", run_angle_array)\n",
    "run_angle_tensor = torch.tensor(\n",
    "    np.load(\"run_angle_array_full.npy\", allow_pickle=False)\n",
    ").float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_shape_walk = walk_angle_tensor.shape\n",
    "pre_shape_run = run_angle_tensor.shape\n",
    "\n",
    "num_frames = min(pre_shape_walk[1], pre_shape_run[1])\n",
    "\n",
    "post_shape_walk = pre_shape_walk[0], num_frames * pre_shape_walk[2]\n",
    "post_shape_run = pre_shape_run[0], num_frames * pre_shape_run[2]\n",
    "\n",
    "walk_angles = walk_angle_tensor[:, :num_frames]  # .reshape(post_shape_walk)\n",
    "run_angles = run_angle_tensor[:, :num_frames]  # .reshape(post_shape_run)\n",
    "walk_samples_shapes_pre = walk_angles.shape\n",
    "run_angles_shapes_pre = run_angles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data data\n",
    "# walk_mean = torch.mean(run_angle_tensor, dim=(0, 1), keepdim=True)\n",
    "# walk_std = torch.std(run_angle_tensor, dim=(0, 1), keepdim=True)\n",
    "# walk_standard = (walk_angles - walk_mean) / walk_std\n",
    "# walk_mean = torch.mean(walk_angle_tensor,  dim=0)\n",
    "# walk_std = torch.std(walk_angle_tensor,  dim=0)\n",
    "\n",
    "# walk_angle_tensor_scaled = (walk_angle_tensor - walk_mean)/walk_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unflattened_shape = walk_angle_tensor.shape\n",
    "unflattened_shape_run = run_angle_tensor.shape\n",
    "walk_angles_reshaped = torch.swapaxes(walk_angle_tensor, 1, 2).reshape(\n",
    "    unflattened_shape[0], unflattened_shape[1] * unflattened_shape[2]\n",
    ")\n",
    "run_angles_reshaped = torch.swapaxes(run_angle_tensor, 1, 2).reshape(\n",
    "    unflattened_shape_run[0], unflattened_shape_run[1] * unflattened_shape_run[2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(walk_standard[1])\n",
    "walk_angles.shape\n",
    "# plt.hist(walk_angles[1][:5], density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk_angles_rev  = torch.swapaxes(walk_angles, 2, 1)\n",
    "data = torch.utils.data.TensorDataset(\n",
    "    walk_angles_reshaped.reshape(\n",
    "        unflattened_shape[0], unflattened_shape[1] * unflattened_shape[2]\n",
    "    )\n",
    ")\n",
    "data_run = torch.utils.data.TensorDataset(\n",
    "    run_angles_reshaped.reshape(\n",
    "        unflattened_shape_run[0], unflattened_shape_run[1] * unflattened_shape_run[2]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "DIR = \"../figures/simple_frame/\"\n",
    "SET_NAME = \"walk_1_auto\"\n",
    "PATH_FIGURES = os.path.join(DIR, SET_NAME)\n",
    "if not os.path.exists(PATH_FIGURES):\n",
    "    os.makedirs(PATH_FIGURES)\n",
    "########\n",
    "\n",
    "\n",
    "event_shape = data[0][0].shape[0]\n",
    "base_dist = torch.distributions.Independent(\n",
    "    torch.distributions.Normal(torch.zeros(event_shape), torch.ones(event_shape)), 1\n",
    ")\n",
    "FOLDS = 1\n",
    "lr_scheduler = lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optim, mode=\"min\", factor=0.2, patience=5, verbose=True\n",
    ")\n",
    "# def get_flow(ji)\n",
    "MODEL_PARAMS = {\n",
    "    \"model\": [sf.utils.get_flow],\n",
    "    \"get_transform\": [sf.utils.get_transform_nflow],\n",
    "    \"base_dist\": [base_dist],\n",
    "    \"Transform\": [nflows.flows.MaskedAutoregressiveFlow],\n",
    "}\n",
    "MODEL_PARAMS_EXPERIMENT = {\n",
    "    \"num_blocks_per_layer\": [2],\n",
    "    \"num_layers\": [5],\n",
    "    \"hidden_features\": [24],\n",
    "}\n",
    "\n",
    "TRAINING_PARAMS = {\n",
    "    \"batch_size\": [500],\n",
    "    \"regularization_param\": [0.0],\n",
    "    \"compute_loss\": [sf.monte_carlo_dkl_loss],\n",
    "    \"post_step\": [sf.get_post_step_lipchitz(5)],\n",
    "}\n",
    "# extend the previous dict with the zip of this\n",
    "TRAINING_PARAMS_EXPERIMENT = {\n",
    "    \"verbose_interval\": [100],\n",
    "    \"optimizer\": [\"ADAM\"],\n",
    "    \"num_epochs\": [200],\n",
    "    \"learning_rate\": [0.01],\n",
    "    # \"lr_scheduler\": [lr_scheduler],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create iterators\n",
    "model_params_iter_1 = create_subdictionary_iterator(MODEL_PARAMS)\n",
    "# model_params_iter = chain.from_iterable((model_params_iter_1, model_params_iter_2))\n",
    "\n",
    "model_exp_iter = create_subdictionary_iterator(MODEL_PARAMS_EXPERIMENT, product=False)\n",
    "exp_model_params_iter = add_dictionary_iterators(model_exp_iter, model_params_iter_1)\n",
    "\n",
    "training_params_iter = create_subdictionary_iterator(TRAINING_PARAMS)\n",
    "training_exp_iter = create_subdictionary_iterator(\n",
    "    TRAINING_PARAMS_EXPERIMENT, product=True\n",
    ")\n",
    "exp_training_params_iter = add_dictionary_iterators(\n",
    "    training_exp_iter, training_params_iter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = k_fold_cv_grid(\n",
    "    model_params=exp_model_params_iter,\n",
    "    fit=fit_FFNN,\n",
    "    training_params=exp_training_params_iter,\n",
    "    data=data,\n",
    "    folds=5,\n",
    "    verbose=True,\n",
    "    trials=1,\n",
    "    partial=True,\n",
    "    shuffle_folds=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the wrapper works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(\n",
    "    path_figures=PATH_FIGURES,\n",
    "    **cv_results,\n",
    "    # plot_function=plot_model_1d,\n",
    "    # function_kwargs=plot_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = cv_results[\"models\"][0][0]\n",
    "# sample = flow.sample([1]).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = base_dist.sample([100])\n",
    "print(\"Log plots:\")\n",
    "\n",
    "print(\"Noise :\", flow.log_prob(noise).mean().item())\n",
    "# print(\"Run data :\", flow.log_prob(run_angles_reshaped[0:1]).mean().item())\n",
    "# print(\"Validation data:\", flow.log_prob().mean().item())\n",
    "print(\"Train data:\", flow.log_prob(data[0:1][0]).mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data[0:1][0]\n",
    "data_2 = data[24:25][0]\n",
    "walk_sample_near_ = flow.bijector(\n",
    "    flow.bijector.inverse(data_1) * 0.5 + flow.bijector.inverse(data_2) * 0.5\n",
    ")\n",
    "# walk_sample_near_ =   data_1*0.5+ data_2*0.5\n",
    "\n",
    "walk_sample_near = walk_sample_near_.reshape(walk_angles[0].shape)\n",
    "pads = (0, 0, 3, 0)\n",
    "walk_sample_near = (\n",
    "    torch.nn.functional.pad(walk_sample_near.T, pads, \"constant\", 0).detach().numpy()\n",
    ")\n",
    "flow.log_prob(walk_sample_near_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.log_prob(walk_sample_near_)\n",
    "# flow.log_prob(data[0:1][0])\n",
    "# flow.log_prob(data[24:25][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skel = copy.deepcopy(run_skeletons[0])\n",
    "\n",
    "test_anim = copy.deepcopy(walk_animations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 0\n",
    "\n",
    "pads = (0, 0, 3, 0)\n",
    "# walk_sample_square = torch.nn.functional.pad(walk_sample.T, pads, \"constant\", 0).detach().numpy()\n",
    "# if frame is not None:\n",
    "#     print(walk_sample_square[:,].shape)\n",
    "#     walk_sample_square =  np.tile(walk_sample_square[:,], [1,10])\n",
    "#     print(walk_sample_square.shape)\n",
    "test_anim.from_numpy_array(walk_sample_near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = mayavi_animate(skel, test_anim, offset=[0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.abs((walk_sample_reformated[7])))\n",
    "anim = mayavi_animate(\n",
    "    skel,\n",
    "    walk_animations[64],\n",
    "    offset=[0, 0, 0],\n",
    "    continuous=True,\n",
    "    fixed_cam=False,\n",
    "    frame_limit=-1,\n",
    "    save_path=\"test.svg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.abs((anim1.to_numpy_array()[7])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 1, 3).reshape((3, 1))  # *np.array([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
