{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from flowtorch.distributions import Flow\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "import shapeflow as sf\n",
    "import sklearn.datasets as datasets\n",
    "import seaborn as sns\n",
    "\n",
    "from signatureshape.animation.src.mayavi_animate import mayavi_animate\n",
    "\n",
    "from deepthermal.FFNN_model import fit_FFNN, FFNN\n",
    "from deepthermal.plotting import plot_result\n",
    "\n",
    "# make reproducible\n",
    "seed = torch.manual_seed(0)\n",
    "\n",
    "# better formats\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = datasets.make_moons(1024, noise=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:, 0], x[:, 1])\n",
    "x = (x - x.mean()) / x.std()\n",
    "plt.scatter(x[:, 0], x[:, 1])\n",
    "p = np.stack((y, np.abs(y - 1)), axis=-1)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data\n",
    "x_tensor = torch.as_tensor(x, dtype=torch.float32)\n",
    "p_tensor = torch.as_tensor(p, dtype=torch.float32)\n",
    "c = torch.arange(2)\n",
    "contexts = len(c)\n",
    "priors = torch.zeros((len(x_tensor), contexts))\n",
    "priors[:, 0] = 0.6\n",
    "priors[:, 1] = 0.4\n",
    "p = priors / torch.sum(priors, dim=1, keepdim=True)\n",
    "data = torch.utils.data.TensorDataset(\n",
    "    x_tensor,\n",
    "    p,\n",
    "    priors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "DIR = \"../figures/frames/\"\n",
    "SET_NAME = \"walk_residual\"\n",
    "PATH_FIGURES = os.path.join(DIR, SET_NAME)\n",
    "if not os.path.exists(PATH_FIGURES):\n",
    "    os.makedirs(PATH_FIGURES)\n",
    "########\n",
    "FOLDS = 5\n",
    "\n",
    "event_shape = data[0][0].shape\n",
    "base_dist = dist.MultivariateNormal(\n",
    "    torch.zeros(event_shape[0]), torch.eye(event_shape[0])\n",
    ")\n",
    "lr_scheduler = lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optim, mode=\"min\", factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "base_dist.batch_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "# stack = 4\n",
    "# flows = sf.nf.get_flow(\n",
    "#     base_dist=base_dist,\n",
    "#     inverse_model=True,\n",
    "#     compose=True,\n",
    "#     get_transform=sf.transforms.NDETransform,\n",
    "#     get_net=[FFNN] * stack,\n",
    "#     activation=[\"tanh\"] * stack,\n",
    "#     n_hidden_layers=[3] * stack,\n",
    "#     neurons=[8] * stack,\n",
    "# )\n",
    "flows = sf.nf.get_flow(\n",
    "    base_dist=base_dist,\n",
    "    inverse_model=True,\n",
    "    compose=False,\n",
    "    get_transform=sf.transforms.NDETransform,\n",
    "    get_net=FFNN,\n",
    "    activation=\"tanh\",\n",
    "    n_hidden_layers=3,\n",
    "    neurons=64,\n",
    "    num_flows=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.5\n",
    "results = fit_FFNN(\n",
    "    model=flows,\n",
    "    batch_size=128,\n",
    "    compute_loss=sf.nf.get_monte_carlo_dkl_loss_conditioned(epsilon=epsilon),\n",
    "    optimizer=\"ADAM\",\n",
    "    # optimizer=lambda p : torch.optim.AdamW(p, lr=2e-3, weight_decay=1e-5),\n",
    "    # post_epoch=sf.nf.get_post_epoch_update_p(epsilon=epsilon),\n",
    "    num_epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    data=data,\n",
    "    folds=FOLDS,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, loss_history, val_history = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the wrapper workps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]\n",
    "plt.plot(loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = base_dist.sample([100])\n",
    "print(\"Log vals=\")\n",
    "\n",
    "print(\"Noise :\", model.log_prob(noise[0:1]).mean().item())\n",
    "print(\"Trian data:\", model.log_prob(data[:][0]).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = 2\n",
    "xmax = -xmin\n",
    "ymax = xmax\n",
    "ymin = xmin\n",
    "pts = 7\n",
    "gridlines = pts * 1000\n",
    "xpts = np.linspace(xmin, xmax, pts)\n",
    "ypts = np.linspace(ymin, ymax, pts)\n",
    "xgrid = np.linspace(xmin, xmax, gridlines)\n",
    "ygrid = np.linspace(ymin, ymax, gridlines)\n",
    "xlines = np.stack([a.ravel() for a in np.meshgrid(xpts, ygrid)])\n",
    "ylines = np.stack([a.ravel() for a in np.meshgrid(xgrid, ypts)])\n",
    "grid = torch.as_tensor(np.concatenate([xlines, ylines], 1).T, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = torch.tensor([[1.0, -0.5]]).T\n",
    "p2 = torch.tensor([[0.0, 1]]).T\n",
    "line = np.linspace(0, 1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1.T * line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = models[0].base_dist.sample([1000])  # p1*line - p1*(1-line)\n",
    "t_points = models[0].bijector.forward(points).detach().numpy()\n",
    "plt.scatter(\n",
    "    t_points[:, 0],\n",
    "    t_points[:, 1],\n",
    "    marker=\".\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "# plt.show()\n",
    "points = models[1].base_dist.sample([1000])  # p1*line - p1*(1-line)\n",
    "t_points = models[1].bijector.forward(points).detach().numpy()\n",
    "plt.scatter(\n",
    "    t_points[:, 0],\n",
    "    t_points[:, 1],\n",
    "    marker=\".\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.scatter(x[:, 0], x[:, 1], alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "X, Y = np.mgrid[-2:2:200j, -2:2:200j]\n",
    "grid = np.stack((X.ravel(), Y.ravel()), axis=1)\n",
    "Z_0 = (\n",
    "    models[0]\n",
    "    .log_prob(torch.tensor(grid, dtype=torch.float32))\n",
    "    .detach()\n",
    "    .numpy()\n",
    "    .reshape((n, n))\n",
    ")\n",
    "Z_1 = (\n",
    "    models[1]\n",
    "    .log_prob(torch.tensor(grid, dtype=torch.float32))\n",
    "    .detach()\n",
    "    .numpy()\n",
    "    .reshape((n, n))\n",
    ")\n",
    "Z = np.where(Z_0 > Z_1, 1, 0)\n",
    "plt.contourf(X, Y, Z, levels=2)\n",
    "plt.show()\n",
    "# plt.scatter(t_points[:, 0], t_points[:, 1],marker=\".\",alpha=0.5, )\n",
    "# # plt.show()\n",
    "# points =models[1].base_dist.sample([1000])# p1*line - p1*(1-line)\n",
    "# t_points = models[1].bijector.forward(points).detach().numpy()\n",
    "# plt.scatter(t_points[:, 0], t_points[:, 1],marker=\".\",alpha=0.5,)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchdyn.nn\n",
    "\n",
    "sample = models[0].base_dist.sample([100])\n",
    "traj = (\n",
    "    models[0]\n",
    "    .bijector.model.model[1]\n",
    "    .trajectory(torchdyn.nn.Augmenter(1, 1)(sample), t_span=torch.linspace(1, 0, 100))\n",
    "    .detach()\n",
    "    .cpu()\n",
    ")\n",
    "traj = traj[:, :, 1:]  # scrapping first dimension := jacobian trace\n",
    "n = 2000\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(sample[:n, 0], sample[:n, 1], s=10, alpha=0.8, c=\"black\")\n",
    "plt.scatter(traj[:, :n, 0], traj[:, :n, 1], s=0.2, alpha=0.2, c=\"olive\")\n",
    "plt.scatter(traj[-1, :n, 0], traj[-1, :n, 1], s=4, alpha=1, c=\"blue\")\n",
    "plt.legend([\"Prior sample z(S)\", \"Flow\", \"z(0)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:, 0], x[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
