{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster the moons dataset\n",
    "\n",
    "In this experiment we cluster simple fake datasets. The default dataset is `moons`, although other datasets can be easily used by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "import shapeflow as sf\n",
    "import sklearn.datasets as datasets\n",
    "import seaborn as sns\n",
    "import extratorch as etorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make reproducible\n",
    "seed = torch.manual_seed(0)\n",
    "\n",
    "# better plotting\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")\n",
    "matplotlib.rcParams.update({\"font.size\": 12})\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")\n",
    "plt.style.use(\"tableau-colorblind10\")\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make moons\n",
    "num_total = 2048\n",
    "num_supervised = 0\n",
    "\n",
    "x, y = datasets.make_moons(num_total, noise=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "x = (x - x.mean()) / x.std()\n",
    "q = np.stack((y, np.abs(y - 1)), axis=-1)\n",
    "\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make priors\n",
    "Since (pretend) we do not know the class of each observation the estimated prior probability is (0.5 + $\\epsilon$,0.5 - $\\epsilon$) for all observations. ($P($`class_1`$)$, $P($`class_2`$)$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SUPERVISED = 0  # no supervised points\n",
    "\n",
    "# define data as tensor\n",
    "x_tensor = torch.as_tensor(x, dtype=torch.float32)\n",
    "\n",
    "# the true posterior probability\n",
    "q_tensor = torch.as_tensor(q, dtype=torch.float32)\n",
    "\n",
    "num_points = q_tensor.shape[0]\n",
    "num_classes = q_tensor.shape[-1]\n",
    "priors = torch.zeros_like(q_tensor)\n",
    "\n",
    "# break symmetry of initial culstering problem\n",
    "eps = torch.rand(len(priors)) * 0.1\n",
    "priors[:, 1] = 1 / num_classes + eps\n",
    "priors[:, 0] = 1 / num_classes - eps\n",
    "\n",
    "# add supervised points if wanted\n",
    "if NUM_SUPERVISED > 0:\n",
    "    priors[:NUM_SUPERVISED] = q_tensor[:NUM_SUPERVISED]\n",
    "\n",
    "init_posterior = priors.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data for training\n",
    "# data =  x, p(c_k|x), p(c_k)\n",
    "data = torch.utils.data.TensorDataset(\n",
    "    x_tensor,\n",
    "    init_posterior,\n",
    "    priors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions that are used for training\n",
    "event_shape = data[0][0].shape\n",
    "base_dist = dist.MultivariateNormal(\n",
    "    torch.zeros(event_shape[0]), torch.eye(event_shape[0])\n",
    ")\n",
    "lr_scheduler = lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optim, mode=\"min\", factor=0.5, patience=10, verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "DIR = \"../figures/moons_cluster/\"\n",
    "SET_NAME = f\"cnf_2\"\n",
    "PATH_FIGURES = os.path.join(DIR, SET_NAME)\n",
    "########\n",
    "\n",
    "TRIALS = 1\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "    \"model\": [sf.nf.get_flow],\n",
    "    \"get_transform\": [sf.transforms.NDETransform],\n",
    "    \"compose\": [False],\n",
    "    \"activation\": [\"tanh\"],\n",
    "    \"get_net\": [etorch.models.FFNN],\n",
    "    \"n_hidden_layers\": [3],\n",
    "    \"neurons\": [8],\n",
    "    \"num_flows\": [priors.shape[-1]],\n",
    "    \"base_dist\": [base_dist],\n",
    "    \"inverse_model\": [True],\n",
    "    \"trace_estimator\": [\"autograd\"],\n",
    "}\n",
    "TRAINING_PARAMS = {\n",
    "    \"optimizer\": [\"ADAM\"],\n",
    "    \"batch_size\": [256],\n",
    "    \"num_epochs\": [200],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"verbose\": [True],\n",
    "    \"lr_scheduler\": [lr_scheduler],\n",
    "    \"compute_loss\": [sf.nf.get_monte_carlo_conditional_dkl_loss()],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_iter = etorch.create_subdictionary_iterator(MODEL_PARAMS, product=True)\n",
    "training_params_iter = etorch.create_subdictionary_iterator(\n",
    "    TRAINING_PARAMS, product=True\n",
    ")\n",
    "\n",
    "cv_results = etorch.k_fold_cv_grid(\n",
    "    fit=etorch.fit_module,\n",
    "    model_params=model_params_iter,\n",
    "    training_params=training_params_iter,\n",
    "    data=data,\n",
    "    verbose=True,\n",
    "    copy_data=True,\n",
    "    trials=TRIALS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot and store the results. Not shown in notebook, but stored in the path `PATH_FIGURES`. For other datasets you might need to change the plotting parameters below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_kwargs = dict(x_lim=(-3, 3), y_lim=(-2, 2), num_samples=500, grid_shape=500)\n",
    "etorch.plotting.plot_result(\n",
    "    path_figures=PATH_FIGURES,\n",
    "    plot_function=sf.plotting.plot_2d_cluster,\n",
    "    **cv_results,\n",
    "    function_kwargs=function_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all the points used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the points used\n",
    "num_points = 2048\n",
    "\n",
    "plt.scatter(x[:num_points, 0], x[:num_points, 1], marker=\".\", color=\"black\")\n",
    "plt.xlim(function_kwargs[\"x_lim\"])\n",
    "plt.ylim(function_kwargs[\"y_lim\"])\n",
    "plt.gca().set_aspect(\"equal\", \"box\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\n",
    "    os.path.join(\n",
    "        PATH_FIGURES,\n",
    "        \"points_total.pdf\",\n",
    "    ),\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all the supervised points used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    x[:NUM_SUPERVISED, 0][y[:NUM_SUPERVISED] == 1],\n",
    "    x[:NUM_SUPERVISED, 1][y[:NUM_SUPERVISED] == 1],\n",
    "    marker=\".\",\n",
    ")\n",
    "plt.scatter(\n",
    "    x[:NUM_SUPERVISED, 0][y[:NUM_SUPERVISED] == 0],\n",
    "    x[:NUM_SUPERVISED, 1][y[:NUM_SUPERVISED] == 0],\n",
    "    marker=\"x\",\n",
    ")\n",
    "plt.xlim(function_kwargs[\"x_lim\"])\n",
    "plt.ylim(function_kwargs[\"y_lim\"])\n",
    "plt.gca().set_aspect(\"equal\", \"box\")\n",
    "plt.axis(\"off\")\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.savefig(\n",
    "    os.path.join(\n",
    "        PATH_FIGURES,\n",
    "        \"points_supervised.pdf\",\n",
    "    ),\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
