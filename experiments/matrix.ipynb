{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test wrapper on moons\n",
    "\n",
    "Test that we can use `flowtorch` with transformations from `nflows`.\n",
    "\n",
    "Example is modifies  from [nflows](https://github.com/bayesiains/nflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from itertools import chain\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "import flowtorch.distributions as ftdist\n",
    "\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation\n",
    "\n",
    "from animation import fetch_animation_id_set, fetch_animations\n",
    "from so3.curves import move_origin_to_zero as move_origin_to_zero_so3\n",
    "from so3.transformations import hatinv\n",
    "from linear import animation_to_SO3\n",
    "from linear.curves import move_origin_to_zero\n",
    "\n",
    "from deepthermal.validation import (\n",
    "    create_subdictionary_iterator,\n",
    "    k_fold_cv_grid,\n",
    "    add_dictionary_iterators,\n",
    ")\n",
    "from deepthermal.FFNN_model import fit_FFNN\n",
    "from deepthermal.plotting import plot_result\n",
    "\n",
    "import shapeflow as sflow\n",
    "\n",
    "# make reproducible\n",
    "seed = torch.manual_seed(0)\n",
    "\n",
    "# better formats\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data as so3\n",
    "# we assume all have the same skeleton\n",
    "print(\"Loading mocap data:\")\n",
    "# walk  data\n",
    "walk_subjects = [\"07\", \"08\"]\n",
    "walk_animations = []\n",
    "for s in walk_subjects:\n",
    "    for t in fetch_animations(100, subject_file_name=(s + \".asf\")):\n",
    "        walk_animations.append(t[1])\n",
    "walk_animations_train_frame = sum(\n",
    "    len(anim.get_frames()) for anim in walk_animations[:18]\n",
    ")\n",
    "\n",
    "# run data\n",
    "run_subjects = [\"09\"]\n",
    "run_animations = []\n",
    "for s in run_subjects:\n",
    "    for t in fetch_animations(100, subject_file_name=(s + \".asf\")):\n",
    "        run_animations.append(t[1])\n",
    "\n",
    "print(\"Convert to array:\")\n",
    "walk_angle_array = sflow.utils.animation_to_eulers(walk_animations)\n",
    "run_angle_array = sflow.utils.animation_to_eulers(run_animations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skel, anim, desc = fetch_animations(1, subject_file_name=walk_subjects[0]+\".asf\")\n",
    "# skel2, anim, desc = fetch_animations(1, subject_file_name=run_subjects[0]+\".asf\")\n",
    "# skel.bones.keys() == skel2.bones.keys()\n",
    "# for bone_name, bone_obj in skel.bones.items():\n",
    "#     pass\n",
    "#     print(bone_name, \":\")\n",
    "#     print([dof for dof in bone_obj.dof], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data since it takes so long to get\n",
    "\n",
    "np.save(\"walk_angle_array.npy\", walk_angle_array)\n",
    "walk_angle_tensor = torch.tensor(\n",
    "    np.load(\"walk_angle_array.npy\", allow_pickle=False)\n",
    ").float()\n",
    "\n",
    "\n",
    "np.save(\"run_angle_array.npy\", run_angle_array)\n",
    "run_angle_tensor = torch.tensor(\n",
    "    np.load(\"run_angle_array.npy\", allow_pickle=False)\n",
    ").float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(walk_animations_train_frame, torch.max(walk_frames), walk_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.utils.data.TensorDataset(walk_angle_tensor[walk_animations_train_frame:])\n",
    "data_val = torch.utils.data.TensorDataset(\n",
    "    walk_angle_8_tensor[:walk_animations_train_frame]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model\n",
    "num_layers = 5\n",
    "event_shape = run_frames.shape[1]\n",
    "base_dist = torch.distributions.Independent(\n",
    "    torch.distributions.Normal(torch.zeros(event_shape), torch.ones(event_shape)), 1\n",
    ")\n",
    "\n",
    "transforms = []\n",
    "for _ in range(num_layers):\n",
    "    transforms.append(ReversePermutation(features=event_shape))\n",
    "    transforms.append(\n",
    "        MaskedAffineAutoregressiveTransform(features=event_shape, hidden_features=4)\n",
    "    )\n",
    "transform = CompositeTransform(transforms)\n",
    "bijector = sflow.WrapInverseModel(model=transform)\n",
    "\n",
    "# flow = ftdist.Flow(bijector=bijector, base_dist=base_dist)\n",
    "# optimizer = optim.Adam(flow.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "DIR = \"../figures/curve_1/\"\n",
    "SET_NAME = \"walk_1_skaled\"\n",
    "PATH_FIGURES = os.path.join(DIR, SET_NAME)\n",
    "if not os.path.exists(PATH_FIGURES):\n",
    "    os.makedirs(PATH_FIGURES)\n",
    "########\n",
    "\n",
    "\n",
    "FOLDS = 1\n",
    "lr_scheduler = lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optim, mode=\"min\", factor=0.2, patience=5, verbose=True\n",
    ")\n",
    "# def get_flow(ji)\n",
    "MODEL_PARAMS = {\"model\": [ftdist.Flow]}\n",
    "MODEL_PARAMS_EXPERIMENT = {\n",
    "    \"bijector\": [bijector],\n",
    "    \"base_dist\": [base_dist],\n",
    "}\n",
    "\n",
    "TRAINING_PARAMS = {\n",
    "    \"batch_size\": [100],\n",
    "    \"regularization_param\": [0.0],\n",
    "    \"compute_loss\": [sflow.monte_carlo_dkl_loss],\n",
    "}\n",
    "# extend the previous dict with the zip of this\n",
    "TRAINING_PARAMS_EXPERIMENT = {\n",
    "    \"verbose_interval\": [1000],\n",
    "    \"optimizer\": [\"ADAM\"],\n",
    "    \"num_epochs\": [1000],\n",
    "    \"learning_rate\": [0.01],\n",
    "    # \"lr_scheduler\": [lr_scheduler],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create iterators\n",
    "model_params_iter_1 = create_subdictionary_iterator(MODEL_PARAMS)\n",
    "# model_params_iter = chain.from_iterable((model_params_iter_1, model_params_iter_2))\n",
    "\n",
    "model_exp_iter = create_subdictionary_iterator(MODEL_PARAMS_EXPERIMENT, product=False)\n",
    "exp_model_params_iter = add_dictionary_iterators(model_exp_iter, model_params_iter_1)\n",
    "\n",
    "training_params_iter = create_subdictionary_iterator(TRAINING_PARAMS)\n",
    "training_exp_iter = create_subdictionary_iterator(\n",
    "    TRAINING_PARAMS_EXPERIMENT, product=False\n",
    ")\n",
    "exp_training_params_iter = add_dictionary_iterators(\n",
    "    training_exp_iter, training_params_iter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = k_fold_cv_grid(\n",
    "    model_params=exp_model_params_iter,\n",
    "    fit=fit_FFNN,\n",
    "    training_params=exp_training_params_iter,\n",
    "    data=data,\n",
    "    folds=FOLDS,\n",
    "    val_data=data_val,\n",
    "    verbose=True,\n",
    "    trials=1,\n",
    "    partial=True,\n",
    "    shuffle_folds=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the wrapper works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(\n",
    "    path_figures=PATH_FIGURES,\n",
    "    **cv_results,\n",
    "    # plot_function=plot_model_1d,\n",
    "    # function_kwargs=plot_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = cv_results[\"models\"][0][0]\n",
    "sample = flow.sample([1]).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = base_dist.sample([100])\n",
    "# print(noise)\n",
    "# print(flow.log_prob(noise))\n",
    "print(\"Log plots:\")\n",
    "\n",
    "print(\"Noise :\", flow.log_prob(noise).mean().item())\n",
    "print(\"Run data :\", flow.log_prob(run_angle_tensor).mean().item())\n",
    "print(\"Validation data:\", flow.log_prob(data_val[:][0]).mean().item())\n",
    "print(\"Trian data:\", flow.log_prob(data[:][0]).mean().item())\n",
    "# print(flow.log_prob(run_frames[:3]))\n",
    "# print(\"values\",noise)\n",
    "# print(\"logprob(values)\",flow.log_prob(noise))\n",
    "# print(flow.log_prob((walk_frames[:10])))\n",
    "# print(walk_frames[:10].shape)\n",
    "# print(\"LogP noise: \",flow.log_prob(sample))\n",
    "# print(\"LogP walk: \",flow.log_prob(walk_frames[:10]))\n",
    "# print(\"LogP walk: \",flow.log_prob(walk_frames[:10]))\n",
    "# base_dist.log_prob(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
