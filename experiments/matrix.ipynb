{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test wrapper on moons\n",
    "\n",
    "Test that we can use `flowtorch` with transformations from `nflows`. \n",
    "\n",
    "Example is modifies  from [nflows](https://github.com/bayesiains/nflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from itertools import chain\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "import flowtorch.distributions as ftdist\n",
    "\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation\n",
    "from nflows.flows import realnvp, autoregressive\n",
    "\n",
    "from animation import fetch_animation_id_set, fetch_animations\n",
    "from so3.curves import move_origin_to_zero as move_origin_to_zero_so3\n",
    "from so3.transformations import hatinv\n",
    "from linear import animation_to_SO3\n",
    "from linear.curves import move_origin_to_zero\n",
    "\n",
    "from deepthermal.validation import (\n",
    "    create_subdictionary_iterator,\n",
    "    k_fold_cv_grid,\n",
    "    add_dictionary_iterators,\n",
    ")\n",
    "from deepthermal.plotting import plot_result\n",
    "\n",
    "from shapeflow import ModuleBijector, WrapInverseModel\n",
    "\n",
    "# make reproducible\n",
    "seed = torch.manual_seed(0)\n",
    "\n",
    "# better formats\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(fetch_animation_id_set(description=\"walk\"))\n",
    "\n",
    "# # fetch data as so3\n",
    "# print(\"loading mocap data:\")\n",
    "# animation_tuples = fetch_animations(1000, description=\"walk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reshape data\n",
    "# skel, anim, desk = animation_tuples[0]\n",
    "# # root elem\n",
    "# num_bones = len(skel.bones) + 1\n",
    "# num_anims =  len(animation_tuples)\n",
    "# total_frames = sum(map(lambda t : len(t[1].get_frames()), animation_tuples))\n",
    "\n",
    "# for s, a, d in animation_tuples:\n",
    "#     assert len(s.bones) +1 == num_bones , f\"not {num_bones} bones\"\n",
    "\n",
    "# anim_array = torch.cat([torch.as_tensor(animation_to_SO3(*t[:2])) for t in  tqdm(animation_tuples)], 1)\n",
    "# frames = torch.moveaxis(anim_array,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data since it takes so long to get\n",
    "# torch.save(frames, 'walk_frames.pt')\n",
    "frames = torch.load(\"walk_frames.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.utils.data.TensorDataset(torch.flatten(frames, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model\n",
    "num_layers = 5\n",
    "event_shape = 23 * 3 * 3\n",
    "base_dist = torch.distributions.Independent(\n",
    "    torch.distributions.Normal(torch.zeros(event_shape), torch.ones(event_shape)), 1\n",
    ")\n",
    "\n",
    "transforms = []\n",
    "for _ in range(num_layers):\n",
    "    transforms.append(ReversePermutation(features=event_shape))\n",
    "    transforms.append(\n",
    "        MaskedAffineAutoregressiveTransform(features=event_shape, hidden_features=4)\n",
    "    )\n",
    "transform = CompositeTransform(transforms)\n",
    "bijector = WrapInverseModel(model=transform)\n",
    "\n",
    "flow = ftdist.Flow(bijector=bijector, base_dist=base_dist)\n",
    "optimizer = optim.Adam(flow.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "DIR = \"../figures/curve_1/\"\n",
    "SET_NAME = \"walk_1\"\n",
    "PATH_FIGURES = os.path.join(DIR, SET_NAME)\n",
    "if not os.path.exists(PATH_FIGURES):\n",
    "    os.makedirs(PATH_FIGURES)\n",
    "########\n",
    "\n",
    "\n",
    "FOLDS = 1\n",
    "N = 128  # training points internal\n",
    "lr_scheduler = lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optim, mode=\"min\", factor=0.2, patience=5, verbose=True\n",
    ")\n",
    "loss_func = get_elastic_metric_loss(r=c1.r, constrain_cost=1e3, verbose=False)\n",
    "no_penalty_loss_func = get_elastic_metric_loss(r=c1.r, constrain_cost=0, verbose=False)\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "    \"input_dimension\": [1],\n",
    "    \"output_dimension\": [1],\n",
    "    \"activation\": [\"tanh\"],\n",
    "    \"n_hidden_layers\": [1, 2, 8, 32, 128],\n",
    "    \"neurons\": [8],\n",
    "}\n",
    "MODEL_PARAMS_2 = {\n",
    "    \"input_dimension\": [1],\n",
    "    \"output_dimension\": [1],\n",
    "    \"activation\": [\"tanh\"],\n",
    "    \"n_hidden_layers\": [2],\n",
    "    \"neurons\": [32],\n",
    "}\n",
    "\n",
    "# extend the previous dict with the zip of this\n",
    "MODEL_PARAMS_EXPERIMENT = {\n",
    "    \"model\": [BResCNN, ResNet],\n",
    "    \"neurons\": [8, 8],\n",
    "    \"kernel_size\": [7, 0],\n",
    "}\n",
    "TRAINING_PARAMS = {\n",
    "    \"batch_size\": [N // 2],\n",
    "    \"regularization_param\": [0],\n",
    "    \"loss_func\": [loss_func],\n",
    "}\n",
    "# extend the previous dict with the zip of this\n",
    "TRAINING_PARAMS_EXPERIMENT = {\n",
    "    \"optimizer\": [\"strong_wolfe\"],\n",
    "    \"num_epochs\": [100],\n",
    "    \"learning_rate\": [1],\n",
    "    \"lr_scheduler\": [lr_scheduler],\n",
    "    \"track_epoch\": [True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the wrapper works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 5000\n",
    "for i in range(num_iter):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = -flow.log_prob(value=data).mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = flow.sample([100]).data\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
